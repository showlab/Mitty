experiment_project: InteractionVideo-Wan-Robot
experiment_name: one2three-DiffSynth-lora-v1
model_id: /raid/share_model/Wan2.2-TI2V-5B-Diffusers
output_root: /raid/workspace1/lc/HumanAndRobot/Output_Model/test/p1_test
use_drop_text: true
text_drop_p: 0.1
use_lora: true
use_DiffSynth: true
training:
  batch_size: 2
  max_steps: 100
  learning_rate: 0.0001
  weight_decay: 0.01
  warmup_steps: 10
  save_val_interval_steps: 50
  accumulate_grad_batches: 2
  gradient_clip_val: null
  precision: bf16-mixed
  accelerator: auto
  strategy: auto
  gradient_checkpointing: true
  benchmark: false
dataset:
  video_root: /raid/workspace1/lc/HumanAndRobot/Datasets/HumanAndRobot_split_resolution/human
  video_root2: /raid/workspace1/lc/HumanAndRobot/Datasets/HumanAndRobot_split_resolution/robot
  first_root: /raid/workspace1/lc/HumanAndRobot/Datasets/HumanAndRobot_split_resolution/robot_first_frame
  is_one2three: true
  height: 224
  width: 416
  sample_n_frames: 50
  fps: 30
  num_workers: 8
  shuffle: true
  drop_last: true
  pin_memory: true
config: configs/train_p1.yaml
seed: 1342
ckpt_path: null
num_nodes: 1
num_gpus: 1
use_wandb: false
lora:
  r: 96
  alpha: 96
